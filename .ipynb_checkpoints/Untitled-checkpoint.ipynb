{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:34:33.470825Z",
     "start_time": "2017-12-06T15:34:23.440830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:34:33.566250Z",
     "start_time": "2017-12-06T15:34:33.470825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:34:36.093719Z",
     "start_time": "2017-12-06T15:34:33.566250Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:49:08.218005Z",
     "start_time": "2017-12-06T15:49:08.211020Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jpg_image_to_array(image_path):\n",
    "  \"\"\"\n",
    "  Loads JPEG image into 3D Numpy array of shape (500, 500)\n",
    "  (width, height, channels)\n",
    "  \"\"\"\n",
    "  with Image.open(image_path) as image:         \n",
    "    im_arr = np.fromstring(image.resize((256,256)).tobytes(), dtype=np.uint8)\n",
    "    im_arr = im_arr.reshape((256, 256, 3))                                   \n",
    "  return im_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T15:24:40.042226Z",
     "start_time": "2017-12-05T15:24:39.954219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10223\n"
     ]
    }
   ],
   "source": [
    "!cat ./labels.csv | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:43:45.970829Z",
     "start_time": "2017-12-06T15:43:45.956379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"./labels.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:43:45.981366Z",
     "start_time": "2017-12-06T15:43:45.972366Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_labels = sorted(list(labels.breed.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:43:18.725420Z",
     "start_time": "2017-12-06T15:43:18.722431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_tr = []\n",
    "label_tr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T15:45:13.538051Z",
     "start_time": "2017-12-06T15:43:48.070237Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open(\"./labels.csv\", mode = 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for index, line in enumerate(lines[1:]):\n",
    "        \n",
    "        file_name, dog_name = line.strip().split(',')\n",
    "\n",
    "        data_tr.append(jpg_image_to_array('./train/' + file_name + '.jpg'))\n",
    "        label_tr.append(list_labels.index(dog_name))\n",
    "        \n",
    "        if index % 500 == 0:\n",
    "            print(index)\n",
    "                       \n",
    "    data_tr = np.array(data_tr, np.float32) / 255.\n",
    "    \n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:57:49.500596Z",
     "start_time": "2017-11-13T13:57:49.382700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(label_tr, sparse = True)\n",
    "\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:57:49.508595Z",
     "start_time": "2017-11-13T13:57:49.503598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_class = one_hot_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:57:49.958593Z",
     "start_time": "2017-11-13T13:57:49.511599Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(data_tr_n,\n",
    "                                                      one_hot_labels,\n",
    "                                                      test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:59:45.682179Z",
     "start_time": "2017-11-13T13:57:49.960598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 18s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights = 'imagenet', include_top=False, input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T14:01:00.127488Z",
     "start_time": "2017-11-13T14:01:00.014120Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-13T14:01:27.862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 9s 12ms/step - loss: 2.6596 - acc: 0.4300 - val_loss: 5.3046 - val_acc: 0.0067\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 9s 13ms/step - loss: 1.2421 - acc: 0.8386 - val_loss: 5.5374 - val_acc: 0.0067\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 9s 13ms/step - loss: 0.5900 - acc: 0.9700 - val_loss: 5.7341 - val_acc: 0.0067\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 9s 13ms/step - loss: 0.3138 - acc: 0.9957 - val_loss: 5.9632 - val_acc: 0.0100\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 9s 12ms/step - loss: 0.2083 - acc: 1.0000 - val_loss: 6.2509 - val_acc: 0.0067\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 9s 13ms/step - loss: 0.1438 - acc: 1.0000 - val_loss: 6.3372 - val_acc: 0.0133\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 9s 12ms/step - loss: 0.1119 - acc: 1.0000 - val_loss: 6.5048 - val_acc: 0.0100\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 9s 12ms/step - loss: 0.0892 - acc: 1.0000 - val_loss: 6.5875 - val_acc: 0.0067\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 9s 12ms/step - loss: 0.0702 - acc: 1.0000 - val_loss: 6.7028 - val_acc: 0.0133\n",
      "Epoch 10/10\n",
      "672/700 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
